{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsmcPBiYtgqC"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from imutils import paths\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"dataset_eyes.zip\" -d \"/content/\""
      ],
      "metadata": {
        "id": "s1f_XhsCO3Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HyperParameters\n",
        "\n",
        "INIT_LR = 1e-4\n",
        "EPOCHS = 5\n",
        "BS = 32"
      ],
      "metadata": {
        "id": "yXTiqzG2O9mK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data and balance dataset.\n",
        "\n",
        "# there are 29 dogs.\n",
        "# dataset_eyes includes 10,860 pics:\n",
        "# 1,941 labeled \"yes\" (69 videos), 8,919 labeled \"no\" (189 videos).\n",
        "\n",
        "# our aim is to take a total of 3,840 pics, ~0.5 of \"yes\" and ~0.5 of \"no\",\n",
        "# which represent most of the dogs.\n",
        "\n",
        "imagePaths = list(paths.list_images(\"eyes up\"))\n",
        "imagePaths.sort()\n",
        "\n",
        "\n",
        "img_yes =imagePaths[8919:]\n",
        "img_yes_copy = img_yes.copy()\n",
        "random.shuffle(img_yes_copy)\n",
        "img_yes_final = img_yes_copy\n",
        "\n",
        "img_no = imagePaths[:8919]\n",
        "img_no_copy = img_no.copy()\n",
        "random.shuffle(img_no_copy)\n",
        "img_no_final = img_no_copy[:1899]\n",
        "\n",
        "# check that pics of every label (yes and no) reresent as many videos as possible.\n",
        "\n",
        "def imge_chcker(img_list):\n",
        "  img_check = []\n",
        "  for path in img_list:\n",
        "    img_check.append(path.split(os.path.sep)[-1].split(\"-\")[-2])\n",
        "  img_set = set(img_check)\n",
        "  return img_set\n",
        "\n",
        "img_check_yes = imge_chcker(img_yes_final)\n",
        "print(\"img_check_yes: \",len(img_check_yes), \"videos\")\n",
        "\n",
        "img_check_no = imge_chcker(img_no_final)\n",
        "print(\"img_check_no: \",len(img_check_no), \"videos\")\n",
        "\n",
        "# and the final data for our model (train + test), 3,840 pics.\n",
        "\n",
        "equalized_imagePaths = img_yes_final + img_no_final\n",
        "random.shuffle(equalized_imagePaths)\n",
        "\n",
        "print (equalized_imagePaths)"
      ],
      "metadata": {
        "id": "y4Cy2f71PR12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing data and labels for model\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for imagePath in equalized_imagePaths:\n",
        "\n",
        "  # extract the class label from the filename\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "\t# load the input image (224x224) and preprocess it\n",
        "\timage = load_img(imagePath, target_size=(224, 224))\n",
        "\timage = img_to_array(image)\n",
        "\timage = preprocess_input(image)\n",
        "\n",
        "\t# update the data and labels lists, respectively\n",
        "\tdata.append(image)\n",
        "\tlabels.append(label)\n",
        "\n",
        "# perform one-hot encoding on the labels\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels, num_classes = 2)\n",
        "\n",
        "# convert the data to NumPy arrays\n",
        "data = np.array(data, dtype=\"float32\")\n"
      ],
      "metadata": {
        "id": "YnkptKcPE35j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing data for Kfold\n",
        "\n",
        "action_units = pd.read_csv('video name and dog name.csv')\n",
        "action_units_new = action_units[['video', 'DogName']]\n",
        "\n",
        "def requested_dogs (dogs):\n",
        "    videos = []\n",
        "    for dog in dogs:\n",
        "        for idx, name in enumerate(action_units_new[\"DogName\"]):\n",
        "            if name == dog:\n",
        "                videos.append(action_units_new[\"video\"][idx])\n",
        "    return videos\n",
        "\n",
        "\n",
        "def new_list_dogs (videos):\n",
        "    specific_dogs = []\n",
        "    specific_dogs_labels = []\n",
        "    for idx, imagePath in enumerate(equalized_imagePaths):\n",
        "        if int(imagePath.split(os.path.sep)[-1].split(\"-\")[-2]) in videos:\n",
        "            specific_dogs.append(data[idx])\n",
        "            specific_dogs_labels.append(labels[idx])\n",
        "    return np.array(specific_dogs), np.array(specific_dogs_labels)\n",
        "\n",
        "\n",
        "# list of 29 dog names arranged by ABC\n",
        "\n",
        "dog_list = list(set(action_units_new[\"DogName\"]))\n",
        "dog_list.sort()\n",
        "\n",
        "# dogs for final test, which we are not training at all\n",
        "\n",
        "indices_final_test = [3, 4, 5]\n",
        "dogs_final_test = [dog_list[index] for index in indices_final_test]\n",
        "X_final_test, y_final_test = new_list_dogs(requested_dogs ([dog_list[index] for index in indices_final_test]))\n",
        "\n",
        "# dogs for train (and validation)\n",
        "\n",
        "dog_list_train =[dog for dog in dog_list if dog not in dogs_final_test]\n",
        "\n"
      ],
      "metadata": {
        "id": "5TyGd1KWKM1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing pics for KFold\n",
        "\n",
        "kf = KFold(n_splits=3)\n",
        "folds = []\n",
        "\n",
        "for train_index, test_index in kf.split(dog_list_train):\n",
        "\n",
        "     print(\"TRAIN:\", train_index.tolist(), \"VALIDATION:\", test_index.tolist())\n",
        "\n",
        "     indices_train, indices_test = train_index.tolist(), test_index.tolist()\n",
        "\n",
        "     X_train, y_train = new_list_dogs(requested_dogs ([dog_list_train[index] for index in indices_train]))\n",
        "     X_test, y_test = new_list_dogs(requested_dogs ([dog_list_train[index] for index in indices_test]))\n",
        "\n",
        "     new_fold = [X_train,y_train,X_test,y_test]\n",
        "     folds.append(new_fold)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzgYTqz4Pqhy",
        "outputId": "6a464aec-6999-41e3-8217-3ee450d94424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25] VALIDATION: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "TRAIN: [0, 1, 2, 3, 4, 5, 6, 7, 8, 18, 19, 20, 21, 22, 23, 24, 25] VALIDATION: [9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
            "TRAIN: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17] VALIDATION: [18, 19, 20, 21, 22, 23, 24, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# train the model\n",
        "\n",
        "fold_no = 1\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "for fold in folds:\n",
        "    X_train, y_train = fold[0],fold[1]\n",
        "    X_test, y_test = fold[2],fold[3]\n",
        "\n",
        "    # construct the model\n",
        "\n",
        "    # construct the training image generator for data augmentation\n",
        "    aug = ImageDataGenerator(featurewise_std_normalization=True, fill_mode=\"nearest\")\n",
        "    it = aug.flow(X_train, y_train)\n",
        "\n",
        "    baseModel = ResNet50(weights=\"imagenet\", include_top=False,\n",
        "      input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "    # construct the head of the model that will be placed on top of the\n",
        "    # the base model\n",
        "    headModel = baseModel.output\n",
        "    headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "    headModel = Flatten(name=\"flatten\")(headModel)\n",
        "    headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "    headModel = Dropout(0.5)(headModel)\n",
        "    headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        "\n",
        "    # place the head FC model on top of the base model (this will become\n",
        "    # the actual model we will train)\n",
        "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "    # loop over all layers in the base model and freeze them so they will\n",
        "    # *not* be updated during the first training process\n",
        "    for layer in baseModel.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "    opt = Adam(learning_rate=INIT_LR)\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt ,metrics=[\"accuracy\"])\n",
        "\n",
        "    # Generate a print\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "    # Fit data to model\n",
        "    history = model.fit(it,\n",
        "                steps_per_epoch=len(X_train) // BS,\n",
        "                epochs=EPOCHS,\n",
        "                verbose=2)\n",
        "\n",
        "    # plot the training loss and accuracy\n",
        "    #print('------------------------------------------------------------------------')\n",
        "    #print(f'Graph for fold {fold_no}')\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(np.arange(0, EPOCHS), history.history[\"loss\"], label=\"train_loss\")\n",
        "    plt.plot(np.arange(0, EPOCHS), history.history[\"accuracy\"], label=\"train_acc\")\n",
        "    plt.title(\"Training Loss and Accuracy\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend(loc=\"lower left\")\n",
        "\n",
        "\n",
        "    # Generate generalization metrics\n",
        "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    acc_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')\n"
      ],
      "metadata": {
        "id": "bBHZCPO84DnN",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}